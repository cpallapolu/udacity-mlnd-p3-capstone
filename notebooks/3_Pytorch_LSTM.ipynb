{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Revenue Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch LSTM Model\n",
    "*Machine Learning Nanodegree Program | Capstone Project*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will be creating a PyTorch LSTM model and compare it with the baseline model I created earlier.\n",
    "\n",
    "### Overview:\n",
    "- Reading the data\n",
    "- Preparing the tensors for the PyTorch Model\n",
    "- Initializing the LSTM model\n",
    "- Training the model with the train dataset\n",
    "- Validating the model using the val dataset\n",
    "- Predict the revenue for customer in test dataset\n",
    "- Visualizing the results\n",
    "- Compare the results with the baseline model\n",
    "- Saving the results to a csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the relevant libraries into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "from os import path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-201308845573\n"
     ]
    }
   ],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix = 'sagemaker/capstone-project'\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the various paths for the training, validation, test files and storing the baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train file: ../datasets/train.zip\n",
      "\n",
      "Validation file: ../datasets/val.zip\n",
      "\n",
      "Validation Prediction file: ../datasets/lstm_pred_val.zip\n",
      "\n",
      "Test file: ../datasets/test.zip\n",
      "\n",
      "Test Prediction file: ../datasets/lstm_pred_test.zip\n",
      "\n",
      "Important Features file: ../datasets/lstm_importances-01.png\n",
      "\n",
      "Input data S3 Train file: s3://sagemaker-us-east-1-201308845573/sagemaker/capstone-project/train.zip\n",
      "\n",
      "Input data S3 directory: s3://sagemaker-us-east-1-201308845573/sagemaker/capstone-project\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../datasets'\n",
    "\n",
    "if not path.exists(data_dir):\n",
    "    raise Exception('{} directory not found.'.format(data_dir))\n",
    "\n",
    "train_file = '{}/{}'.format(data_dir, 'train.zip')\n",
    "print('\\nTrain file: {}'.format(train_file))\n",
    "\n",
    "val_file = '{}/{}'.format(data_dir, 'val.zip')\n",
    "print('\\nValidation file: {}'.format(val_file))\n",
    "\n",
    "pred_val_file = '{}/{}'.format(data_dir, 'lstm_pred_val.zip')\n",
    "print('\\nValidation Prediction file: {}'.format(pred_val_file))\n",
    "\n",
    "test_file = '{}/{}'.format(data_dir, 'test.zip')\n",
    "print('\\nTest file: {}'.format(test_file))\n",
    "\n",
    "pred_test_file = '{}/{}'.format(data_dir, 'lstm_pred_test.zip')\n",
    "print('\\nTest Prediction file: {}'.format(pred_test_file))\n",
    "\n",
    "imp_features_file = '{}/{}'.format(data_dir, 'lstm_importances-01.png')\n",
    "print('\\nImportant Features file: {}'.format(imp_features_file))\n",
    "\n",
    "input_s3_train_file = sagemaker_session.upload_data(path=train_file, bucket=bucket, key_prefix=prefix)\n",
    "print('\\nInput data S3 Train file: {}'.format(input_s3_train_file))\n",
    "\n",
    "input_s3_dir = 's3://{}/{}'.format(bucket, prefix)\n",
    "print('\\nInput data S3 directory: {}'.format(input_s3_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker/capstone-project/train.zip\n",
      "\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "empty_check = []\n",
    "\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('\\nTest passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to load the dataset from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(zip_path):\n",
    "    df = pd.read_csv(\n",
    "        zip_path,\n",
    "        dtype={'fullVisitorId': 'str'},\n",
    "        compression='zip'\n",
    "    )\n",
    "    \n",
    "    [rows, columns] = df.shape\n",
    "\n",
    "    print('Loaded {} rows with {} columns from {}.'.format(\n",
    "        rows, columns, zip_path\n",
    "    ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 765707 rows with 26 columns from ../datasets/train.zip.\n",
      "Loaded 137946 rows with 26 columns from ../datasets/val.zip.\n",
      "Loaded 804684 rows with 25 columns from ../datasets/test.zip.\n",
      "\n",
      "CPU times: user 12.2 s, sys: 459 ms, total: 12.6 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df = load_data(train_file)\n",
    "val_df = load_data(val_file)\n",
    "test_df = load_data(test_file)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>geoNetwork.city</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>geoNetwork.country</th>\n",
       "      <th>...</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>trafficSource.referralPath</th>\n",
       "      <th>totals.bounces</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.newVisits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>0.5714285714</td>\n",
       "      <td>0.2844827586</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.8695652174</td>\n",
       "      <td>0.3951781971</td>\n",
       "      <td>0.4000000000</td>\n",
       "      <td>0.9251101322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1133370432</td>\n",
       "      <td>0.8000000000</td>\n",
       "      <td>0.4168336673</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0884048864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>0.5714285714</td>\n",
       "      <td>0.3534482759</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.2608695652</td>\n",
       "      <td>0.5796645702</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0484581498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1133370432</td>\n",
       "      <td>0.8000000000</td>\n",
       "      <td>0.4168336673</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0899785187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>0.5714285714</td>\n",
       "      <td>0.2844827586</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.8695652174</td>\n",
       "      <td>0.4968553459</td>\n",
       "      <td>0.6000000000</td>\n",
       "      <td>0.8149779736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1133370432</td>\n",
       "      <td>0.8000000000</td>\n",
       "      <td>0.4168336673</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0895117291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>4763447161404445595</td>\n",
       "      <td>0.5714285714</td>\n",
       "      <td>0.6724137931</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.2173913043</td>\n",
       "      <td>0.5796645702</td>\n",
       "      <td>0.4000000000</td>\n",
       "      <td>0.4096916300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2980894083</td>\n",
       "      <td>0.8000000000</td>\n",
       "      <td>0.4168336673</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0900122290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>27294437909732085</td>\n",
       "      <td>0.5714285714</td>\n",
       "      <td>0.2844827586</td>\n",
       "      <td>0.5000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.5796645702</td>\n",
       "      <td>0.6000000000</td>\n",
       "      <td>0.9559471366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1133370432</td>\n",
       "      <td>0.8000000000</td>\n",
       "      <td>0.4168336673</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0025380711</td>\n",
       "      <td>0.0881587000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   totals.transactionRevenue        fullVisitorId  channelGrouping  \\\n",
       "0               0.0000000000  1131660440785968503     0.5714285714   \n",
       "1               0.0000000000   377306020877927890     0.5714285714   \n",
       "2               0.0000000000  3895546263509774583     0.5714285714   \n",
       "3               0.0000000000  4763447161404445595     0.5714285714   \n",
       "4               0.0000000000    27294437909732085     0.5714285714   \n",
       "\n",
       "   device.browser  device.deviceCategory  device.isMobile  \\\n",
       "0    0.2844827586           0.0000000000     0.0000000000   \n",
       "1    0.3534482759           0.0000000000     0.0000000000   \n",
       "2    0.2844827586           0.0000000000     0.0000000000   \n",
       "3    0.6724137931           0.0000000000     0.0000000000   \n",
       "4    0.2844827586           0.5000000000     1.0000000000   \n",
       "\n",
       "   device.operatingSystem  geoNetwork.city  geoNetwork.continent  \\\n",
       "0            0.8695652174     0.3951781971          0.4000000000   \n",
       "1            0.2608695652     0.5796645702          1.0000000000   \n",
       "2            0.8695652174     0.4968553459          0.6000000000   \n",
       "3            0.2173913043     0.5796645702          0.4000000000   \n",
       "4            0.0000000000     0.5796645702          0.6000000000   \n",
       "\n",
       "   geoNetwork.country  ...  trafficSource.keyword  trafficSource.medium  \\\n",
       "0        0.9251101322  ...           0.1133370432          0.8000000000   \n",
       "1        0.0484581498  ...           0.1133370432          0.8000000000   \n",
       "2        0.8149779736  ...           0.1133370432          0.8000000000   \n",
       "3        0.4096916300  ...           0.2980894083          0.8000000000   \n",
       "4        0.9559471366  ...           0.1133370432          0.8000000000   \n",
       "\n",
       "   trafficSource.source  trafficSource.referralPath  totals.bounces  \\\n",
       "0          0.4168336673                1.0000000000    1.0000000000   \n",
       "1          0.4168336673                1.0000000000    1.0000000000   \n",
       "2          0.4168336673                1.0000000000    1.0000000000   \n",
       "3          0.4168336673                1.0000000000    1.0000000000   \n",
       "4          0.4168336673                1.0000000000    1.0000000000   \n",
       "\n",
       "   totals.hits  totals.newVisits  totals.pageviews  visitNumber  \\\n",
       "0 0.0000000000      1.0000000000      0.0000000000 0.0000000000   \n",
       "1 0.0000000000      1.0000000000      0.0000000000 0.0000000000   \n",
       "2 0.0000000000      1.0000000000      0.0000000000 0.0000000000   \n",
       "3 0.0000000000      1.0000000000      0.0000000000 0.0000000000   \n",
       "4 0.0000000000      0.0000000000      0.0000000000 0.0025380711   \n",
       "\n",
       "   visitStartTime  \n",
       "0    0.0884048864  \n",
       "1    0.0899785187  \n",
       "2    0.0895117291  \n",
       "3    0.0900122290  \n",
       "4    0.0881587000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove this at the end\n",
    "\n",
    "import torch\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "train_y = np.log1p(train_df['totals.transactionRevenue'].values)\n",
    "train_y = torch.from_numpy(train_y).float().squeeze()\n",
    "\n",
    "train_X = train_df.drop(['totals.transactionRevenue', 'fullVisitorId'], axis=1).values\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='lstm_train.py',\n",
    "    source_dir='../models/pytorch/',\n",
    "    role=role,\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.2',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    hyperparameters={\n",
    "        'input_dim': 24,\n",
    "        'epochs': 10,\n",
    "        'batch-size': 1024\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-27 16:01:28 Starting - Starting the training job...\n",
      "2020-01-27 16:01:30 Starting - Launching requested ML instances......\n",
      "2020-01-27 16:02:33 Starting - Preparing the instances for training...\n",
      "2020-01-27 16:03:28 Downloading - Downloading input data......\n",
      "2020-01-27 16:04:28 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,059 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,062 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,075 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,076 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,329 sagemaker-containers INFO     Module lstm_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,329 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,329 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:30,329 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: lstm-train\n",
      "  Building wheel for lstm-train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for lstm-train (setup.py): finished with status 'done'\n",
      "  Created wheel for lstm-train: filename=lstm_train-1.0.0-py2.py3-none-any.whl size=11431 sha256=6e4ccfa6687d14a279b9fd874a152f81072ac7319065e0801c3e61a3e79b7b8c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rlon7zvg/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built lstm-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: lstm-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed lstm-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3; however, version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:32,322 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-27 16:04:32,336 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 1024,\n",
      "        \"input_dim\": 24,\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-27-16-01-27-668\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-201308845573/pytorch-training-2020-01-27-16-01-27-668/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"lstm_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"lstm_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":1024,\"epochs\":10,\"input_dim\":24}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=lstm_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=lstm_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-201308845573/pytorch-training-2020-01-27-16-01-27-668/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":1024,\"epochs\":10,\"input_dim\":24},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-27-16-01-27-668\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-201308845573/pytorch-training-2020-01-27-16-01-27-668/source/sourcedir.tar.gz\",\"module_name\":\"lstm_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"lstm_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"1024\",\"--epochs\",\"10\",\"--input_dim\",\"24\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIM=24\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m lstm_train --batch-size 1024 --epochs 10 --input_dim 24\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with input_dim 24, hidden_dim 100, outout_dim: 1.\u001b[0m\n",
      "\u001b[34mEpoch: 1... RSMELoss: 1433.8389639854...\u001b[0m\n",
      "\u001b[34mEpoch: 2... RSMELoss: 1411.3648309708...\u001b[0m\n",
      "\u001b[34mEpoch: 3... RSMELoss: 1408.9556663632...\u001b[0m\n",
      "\u001b[34mEpoch: 4... RSMELoss: 1405.9271305203...\u001b[0m\n",
      "\u001b[34mEpoch: 5... RSMELoss: 1406.3072042465...\u001b[0m\n",
      "\u001b[34mEpoch: 6... RSMELoss: 1406.7832317948...\u001b[0m\n",
      "\u001b[34mEpoch: 7... RSMELoss: 1406.7636879086...\u001b[0m\n",
      "\u001b[34mEpoch: 8... RSMELoss: 1405.3626196384...\u001b[0m\n",
      "\u001b[34mEpoch: 9... RSMELoss: 1406.2804746628...\u001b[0m\n",
      "\n",
      "2020-01-27 16:07:31 Uploading - Uploading generated training model\u001b[34mEpoch: 10... RSMELoss: 1405.7278135419...\u001b[0m\n",
      "\u001b[34m2020-01-27 16:07:27,224 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-27 16:07:38 Completed - Training job completed\n",
      "Training seconds: 250\n",
      "Billable seconds: 250\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': input_s3_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    role=role,\n",
    "    framework_version='1.2',\n",
    "    entry_point='lstm_predict.py',\n",
    "    source_dir='../models/pytorch'\n",
    ")\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(dataset, size=1024):\n",
    "    for i in range(0, len(dataset), size):  \n",
    "        yield dataset[i:(i + size)] \n",
    "        \n",
    "def predict_batch(predictor, dataset):\n",
    "    pred_arr = np.array([])\n",
    "    \n",
    "    for next_batch in get_batches(dataset):\n",
    "        temp_pred = predictor.predict(next_batch)\n",
    "        \n",
    "        pred_arr = np.append(pred_arr, temp_pred)\n",
    "    \n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_id = val_df['fullVisitorId'].values\n",
    "val_y = val_df['totals.transactionRevenue'].values\n",
    "\n",
    "val_X = val_df.drop(['totals.transactionRevenue', 'fullVisitorId'], axis=1).values\n",
    "val_X = val_X.reshape(val_X.shape[0], 1, val_X.shape[1])\n",
    "\n",
    "pred_val = predict_batch(predictor, val_X)\n",
    "\n",
    "pred_val[pred_val < 0] = 0\n",
    "\n",
    "pred_val_data = {\n",
    "    'fullVisitorId': val_id,\n",
    "    'transactionRevenue': val_y,\n",
    "    'predictedRevenue': np.expm1(pred_val)\n",
    "}\n",
    "\n",
    "pred_val_df = pd.DataFrame(pred_val_data)\n",
    "\n",
    "pred_val_df = pred_val_df.groupby('fullVisitorId')['transactionRevenue', 'predictedRevenue'].sum().reset_index()\n",
    "\n",
    "pred_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsme_val = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        np.log1p(pred_val_df['transactionRevenue'].values),\n",
    "        np.log1p(pred_val_df['predictedRevenue'].values)\n",
    "    )\n",
    ")\n",
    "\n",
    "print('\\nRSME for validation data set: {:.10f}\\n'.format(rsme_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df['fullVisitorId'].values\n",
    "test_X = test_df.drop(['fullVisitorId'], axis=1)\n",
    "\n",
    "test_X = test_X.reshape(test_X.shape[0], 1, test_X.shape[1])\n",
    "\n",
    "pred_val = predict_batch(predictor, val_X)\n",
    "\n",
    "pred_test[pred_test < 0] = 0\n",
    "\n",
    "pred_test_data = {\n",
    "    'fullVisitorId': test_id,\n",
    "    'predictedRevenue': np.expm1(pred_test)\n",
    "}\n",
    "\n",
    "pred_test_df = pd.DataFrame(pred_test_data)\n",
    "\n",
    "pred_test_df = pred_test_df.groupby('fullVisitorId')['predictedRevenue'].sum().reset_index()\n",
    "\n",
    "pred_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_df.to_csv(pred_val_file, index=False, compression='zip')\n",
    "\n",
    "pred_test_df.to_csv(pred_test_file, index=False, compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(predictor):\n",
    "    try:\n",
    "        predictor.delete_endpoint()\n",
    "        print('Deleted {}'.format(predictor.endpoint))\n",
    "    except: \n",
    "        print('Already deleted: {}'.format(predictor.endpoint))\n",
    "        \n",
    "\n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
